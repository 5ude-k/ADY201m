name: Crawl 2 Notebooks & Update SQL Daily

on:
  workflow_dispatch:          # Cho phép chạy thủ công
  schedule:
    - cron: "0 0 * * *"       # Chạy tự động mỗi ngày 00:00 UTC (07:00 VN)

jobs:
  update-sql:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install pandas jupyter nbconvert beautifulsoup4 requests openpyxl

      # --- 1️⃣ Chạy notebook BeautifulSoup ---
      - name: Run BeautifulSoup crawler
        run: |
          jupyter nbconvert --to python beautifulsoupcaocao.ipynb --output beautifulsoupcaocao.py
          python beautifulsoupcaocao.py > crawl_output_1.txt

      # --- 2️⃣ Chạy notebook APICAO ---
      - name: Run APICAO crawler
        run: |
          jupyter nbconvert --to python APICAO.ipynb --output APICAO.py
          python APICAO.py > crawl_output_2.txt

      # --- 3️⃣ Gộp CSV và cập nhật SQL ---
      - name: Merge CSV outputs and update SQL
        run: |
          python - <<'EOF'
          import pandas as pd
          import os
          from io import StringIO

          sql_file = "phongtro_danang.sql"

          def extract_csv(path):
              """Tìm phần CSV trong file output (bắt đầu từ dòng 'location,')"""
              with open(path, "r", encoding="utf-8") as f:
                  lines = f.read().splitlines()
              for i, line in enumerate(lines):
                  if line.lower().startswith("location,"):
                      csv_str = "\n".join(lines[i:])
                      return pd.read_csv(StringIO(csv_str))
              return pd.DataFrame()

          # --- Đọc output từ 2 notebook ---
          df1 = extract_csv("crawl_output_1.txt")
          df2 = extract_csv("crawl_output_2.txt")

          df = pd.concat([df1, df2], ignore_index=True).drop_duplicates()

          if df.empty:
              print("⚠️ Không có dữ liệu để cập nhật.")
              exit(0)

          # Làm sạch cơ bản
          if "location" in df.columns:
              df["location"] = df["location"].astype(str).str.replace("'", "", regex=False)

          # Đọc SQL cũ
          existing_lines = set()
          if os.path.exists(sql_file):
              with open(sql_file, "r", encoding="utf-8") as f:
                  existing_lines = set(line.strip() for line in f if line.strip())

          # Sinh câu INSERT
          new_lines = []
          for _, row in df.iterrows():
              def v(x):
                  if pd.isna(x) or x in ["", "None", "nan"]:
                      return "NULL"
                  return f"'{str(x).replace(\"'\", \"''\")}'"

              line = (
                  f"INSERT INTO phongtro_danang VALUES ("
                  f"{v(row.get('location'))}, {v(row.get('price'))}, {v(row.get('area'))}, "
                  f"{v(row.get('date_posted'))}, {v(row.get('fridge'))}, "
                  f"{v(row.get('washer'))}, {v(row.get('air_condition'))}, {v(row.get('wifi'))});"
              )

              if line not in existing_lines:
                  new_lines.append(line)

          # Ghi thêm các dòng mới
          if new_lines:
              with open(sql_file, "a", encoding="utf-8") as f:
                  for line in new_lines:
                      f.write("\n" + line)
              print(f"✅ Đã thêm {len(new_lines)} dòng mới vào {sql_file}")
          else:
              print("⚠️ Không có dòng mới để thêm (tất cả đã tồn tại).")
          EOF

      # --- 4️⃣ Commit & Push ---
      - name: Commit & Push Changes
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add phongtro_danang.sql || true
          git commit -m "Daily update from both notebooks (merged unique rows)" || echo "No changes"
          git push || echo "No changes to push"
